{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the questions below.  When finished, export this notebook as a pdf or html file, and then submit that file to the appropriate assignment in the Google classroom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What are the three sources of error for a given model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Irreducible error, bias, and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Can these error sources be measured or observed directly?  If they can, how does one measure them?  If they cannot, how do we ensure that all sources of error are minimized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We can not observe them by looking at the model. We can not reduce irreducible error, but we can reduce bias by not oversimplifying our model, and we can reduce variance by not paying too much attention to every point. So in order to reduce error as a whole, you want to find the seet spot so that we aren't paying too much attention to every point, but we are not simplfying the model too mcuh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. In your own words, explain each source of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Bias is the difference between the prediction of our model and the real value we are trying to predict at each point.\n",
    "Variance is the variablility of our model at each point.\n",
    "Irreducible error is the inevitable error that all models will have, since data is never perfectly distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Which source of error is associted with \"overfitting\" a model, and which is associated with \"underfitting?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. High variance overfits our model, while high bias underfits it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What is a hyperparameter? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.  It is a parameter that is not directly in the model, but is necessary to get accurate in order to make a good model. Examples include, p and lambda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Describe the k-folds cross validation framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. This is where we divide our data in to k different \"folds\"(ussually 10). We take all but one of the folds and train our model with it. Then we test it on the last fold of the data that we took out. Then we repeat this process k times, taking out a different fold each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Describe the Train - Validate - Test framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Generally in this type of framework, we take our data and split it into training data(60%), validation data(20%) and test data(20%). We use our training data to train our data, then we test it agasint the validation set. We make the requisite changes to the data to get a good model, and only when we have ouor model do we take out the test set and run our model on it and that is the outcome we report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. What does it mean for a data set to be \"imbalanced,\" and how do we take this into consideration during cross validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. If it is imbalaned, this means we have very few instances of the thing we are trying to find in our data. In order to make sure that all or most of these instances don't end up in our training or all end up in our test set, we can stratify our data to purposely put the right percentage of instances in our training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. When applying $L^2$ Regularization to a model, how does $\\lambda_2$ affect the model parameters?  That is, what is the effect on the model parameters, and by what mechanism is this effect achieved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. If we add a lambda to our model, we raise all of the values up which will flatten out our model, so our model will not be pulled up so hard from a couple of outliers. It increases our bias, but lowers our variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. From the probabilistic perspective, explain how $L^2$ Regularization introduces bias into a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. We are adding something to our OLS, which is our best model for the training set in terms of R^2 which introduces bias. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
